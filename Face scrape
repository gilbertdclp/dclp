#>>> response.xpath('//title')
#[<Selector xpath='//title' data='<title>Quotes to Scrape</title>'>]
#>>> response.xpath('//title/text()').extract_first()
#'Quotes to Scrape'

#>>> response.css('title::text').extract()
#['Quotes to Scrape']


#import scrapy
import re
import time
import scrapy
import random
import json
import locale
from urllib2 import urlopen as uReq
from bs4 import BeautifulSoup as soup


#class QuotesSpider(scrapy.Spider):
#name = "soups"

user_agent = "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36"

url = 'https://www.facebook.com/widgets/like.php?width=280&show_faces=1&layout=standard&href=http%3A%2F%2Fwww.imdb.com%2Ftitle%2Ftt1396484%2F&colorscheme=light'

#        'https://www.facebook.com/widgets/like.php?width=280&show_faces=1&layout=standard&href=http%3A%2F%2Fwww.imdb.com%2Ftitle%2Ftt1396484%2F&colorscheme=light',
    

#    def parse(self, response):
#        for quote in response.xpath('//td[@class="_51m- _51mw"]'):
#            yield {
#                'likes': quote.xpath('//span[@id="u_0_3"]/text()').extract()[0:]



#    def parse(self, response):
#        for quote in response.xpath('//div'):
#            yield {
#                'text': quote.xpath('span/text()').extract_first(),
#                'author': quote.xpath('span/small/text()').extract_first(),
#                'tags': quote.xpath('div/a/text()').extract(),


#            }

#time.sleep(random.uniform(0, 0.25)) # randomly snooze a time within [0, 0.4] second
print url

uClient = uReq(url)
content = uClient.read()
uClient.close()
#page_soup = soup(content, "html.parser")
page_soup = soup(content, "lxml-xml")
soup_output = page_soup.find_all(id="u_0_3")
cut = soup_output.xpath('span/text()').extract()[0]
print cut

#soups = soup(content, "lxml")
#sentence = soups.find_all(itemprop="author")[0].span.string 
# get sentence like: "43K people like this" #stick xpath extract statement here
 #           sentence = num_likes.xpath('//tbody/tr/td/table/tbody/tr/td/div/span/text()').extract(),
#num_likes = sentence.split(" ")[0]

#print num_likes


       
